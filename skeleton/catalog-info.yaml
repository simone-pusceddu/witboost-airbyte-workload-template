apiVersion: backstage.io/v1alpha1
kind: Component
metadata:
  name: ${{ values.identifier }}
  description: ${{ values.description | dump }}
  annotations:
    gitlab.com/project-slug: ${{ values.destination.owner + "/" + values.destination.repo }}
    backstage.io/techdocs-ref: dir:.
  tags:
    - aws
    - cdp
    - airflow
    - workload
spec:
  type: workload
  lifecycle: experimental
  owner: ${{ values.developmentGroup | dump }}
  system: ${{ values.dataproduct | dump }}
  domain: ${{ values.domain | dump }}
  mesh:
    name: ${{ values.name | dump }}
    fullyQualifiedName: ${{ values.fullyQualifiedName | dump }}
    description: ${{ values.description | dump }}
    kind: workload
    version: ${{ values.identifier.split(".")[2] + ".0.0" }}
    infrastructureTemplateId: ${{ values.infrastructureTemplateId }}
    useCaseTemplateId: ${{ values.useCaseTemplateId }}
    dependsOn: {% if values.dependsOn | length > 0 %}{% for i in values.dependsOn %}
      - ${{ i }}{% endfor %}{% else %}[]{% endif %}
    platform: CDP on AWS
    technology: airflow
    workloadType: batch
    connectionType: DataPipeline
    tags: []
    readsFrom: {% if values.readsFrom | length > 0 %}{% for i in values.readsFrom %}
      - ${{ i }}{% endfor %}{% else %}[]{% endif %}
    specific: 
      cdeService: ${{ values.service }}
      cdeCluster: ${{ values.cluster }}
      dagFile: s3://${{ values.bucket }}/${{ values.domain }}/${{ values.dataproduct }}/0.0.0/airflow-dag.py
      jobName: ${{ values.jobName }}
